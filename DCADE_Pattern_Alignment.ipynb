{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import suffix_tree\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from read_file import read_file\n",
    "import node_op\n",
    "import sys\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nVariable: find_encode\\n- 0: Use specified encode\\n- 1: Choose from candidate\\n--------------------------\\nVariable: brute (Loop all combination)\\n- 0: Don't loop\\n- 1: loop\\n--------------------------\\nVariable: drop_last (Last pattern handling)\\n- 0: handle it\\n- 1: Only do once MSA\\n--------------------------\\nVariable: seg_method (Segmentation method)\\n- 0: Unique MT\\n- 1: Split by top repeat\\n--------------------------\\nVariable: ignore_len (ignore maximal repeat <= len)\\n- 0: Off\\n- 1: On\\n--------------------------\\nVariable: MINIMAL_REPEAT (Minimal repeat count)\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_encode = 1\n",
    "brute = 1\n",
    "drop_last = 1\n",
    "seg_method = 1\n",
    "ignore_len = 2\n",
    "MINIMAL_REPEAT = 2\n",
    "\"\"\"\n",
    "Variable: find_encode\n",
    "- 0: Use specified encode\n",
    "- 1: Choose from candidate\n",
    "--------------------------\n",
    "Variable: brute (Loop all combination)\n",
    "- 0: Don't loop\n",
    "- 1: loop\n",
    "--------------------------\n",
    "Variable: drop_last (Last pattern handling)\n",
    "- 0: handle it\n",
    "- 1: Only do once MSA\n",
    "--------------------------\n",
    "Variable: seg_method (Segmentation method)\n",
    "- 0: Unique MT\n",
    "- 1: Split by top repeat\n",
    "--------------------------\n",
    "Variable: ignore_len (ignore maximal repeat <= len)\n",
    "- 0: Off\n",
    "- 1: On\n",
    "--------------------------\n",
    "Variable: MINIMAL_REPEAT (Minimal repeat count)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary(string, length):\n",
    "    while len(string) != length:\n",
    "        string = '0' + string\n",
    "    return string\n",
    "\n",
    "sys.setrecursionlimit(1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rick\\Desktop\\test\\2\\Output\\TXT\\TableA.txt\n"
     ]
    }
   ],
   "source": [
    "#current_path = os.path.join(os.path.expanduser(\"~\"), \"jupyter\", \"Fix_DCADE_Output\")\n",
    "#current_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\", \"DCADE\", \"TAM\")\n",
    "#current_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\", \"test\", \"1\")\n",
    "current_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\", \"test\", \"2\")\n",
    "#current_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\", \"DCADE\", \"RISE_\", \"R01\")\n",
    "input_file_path = os.path.join(current_path, \"Output\", \"TXT\", \"TableA.txt\")\n",
    "print(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = read_file(input_file_path)\n",
    "content = f[0]\n",
    "recb_start = f[1]\n",
    "recb_end = f[2]\n",
    "tag = f[3]\n",
    "ids = f[4]\n",
    "classes = f[5]\n",
    "pathid = f[6]\n",
    "parentid = f[7]\n",
    "tecid = f[8]\n",
    "cecid = f[9]\n",
    "encoding = f[10]\n",
    "col = f[11]\n",
    "others = f[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique MT's index:\n",
      " [3, 10, 11, 12, 13, 14, 184, 211, 236, 1457, 1458, 1467, 1487]\n"
     ]
    }
   ],
   "source": [
    "tec_dict = {}\n",
    "unique_mt = []\n",
    "for node in range(len(col)):\n",
    "    if col[node] == 'MT':\n",
    "        if tecid[node] not in tec_dict.keys():\n",
    "            tec_dict[tecid[node]] = [node]\n",
    "        else:\n",
    "            tec_dict[tecid[node]].append(node)\n",
    "for key in tec_dict.keys():\n",
    "    if len(tec_dict[key]) == 1:\n",
    "        unique_mt += tec_dict[key]\n",
    "print(\"Unique MT's index:\\n\", unique_mt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate node in to unicode for suffix tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change `encode_option` to use different attribute to encode leafnodes.\n",
    "<br><br>\n",
    "Leafnodes will have same encoding if they have same attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================ \n",
      "Progress: 0 %\t 1 / 466\n",
      "================================================================================\n",
      "000000111\n",
      "0 (45, 'ĭŻį') \t0.17\n",
      "1 (15, 'īĬĭĮį') \t0.43\n",
      "Set count: 2 Score: 0.30\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Best Update\n",
      "\n",
      "000001011\n",
      "0 (160, 'bcb') \t0.55\n",
      "1 (128, 'NNN') \t0.01\n",
      "2 (6, 'jkl') \t0.43\n",
      "3 (5, 'JJJ') \t0.08\n",
      "4 (6, 'VUW') \t0.75\n",
      "5 (4, 'AAA') \t0.09\n",
      "6 (3, 'KKK') \t0.09\n",
      "7 (4, '[\\\\[') \t0.83\n",
      "Set count: 8 Score: 0.35\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Best Update\n",
      "\n",
      "000001101\n",
      "0 (45, 'ĲơĴ') \t0.20\n",
      "1 (15, 'İıĲĳĴ') \t0.46\n",
      "Set count: 2 Score: 0.33\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================ \n",
      "Progress: 1 %\t 5 / 466\n",
      "================================================================================\n",
      "000010011\n",
      "0 (989, 'CCC') \t0.00\n",
      "1 (4, 'AAA') \t0.08\n",
      "Set count: 2 Score: 0.04\n",
      "--------------------------------------------------------------------------------\n",
      "000011010\n",
      "0 (160, 'aba') \t0.55\n",
      "1 (128, 'MMM') \t0.01\n",
      "2 (6, 'ijk') \t0.43\n",
      "3 (5, 'AAA') \t0.08\n",
      "4 (6, 'UTV') \t0.75\n",
      "5 (5, 'III') \t0.08\n",
      "6 (4, 'Z[Z') \t0.83\n",
      "7 (3, 'JJJ') \t0.09\n",
      "Set count: 8 Score: 0.35\n",
      "--------------------------------------------------------------------------------\n",
      "000100011\n",
      "0 (1206, 'KKK') \t0.08\n",
      "1 (158, 'HHH') \t0.01\n",
      "2 (26, 'MMM') \t0.09\n",
      "3 (7, 'GGG') \t0.09\n",
      "4 (4, 'AAA') \t0.08\n",
      "Set count: 5 Score: 0.07\n",
      "--------------------------------------------------------------------------------\n",
      "000101001\n",
      "0 (160, 'cdc') \t0.55\n",
      "1 (128, 'OOO') \t0.01\n",
      "2 (6, 'klm') \t0.43\n",
      "3 (5, 'JJJ') \t0.09\n",
      "4 (6, 'WVX') \t0.75\n",
      "5 (4, 'AAA') \t0.09\n",
      "6 (4, '\\\\]\\\\') \t0.83\n",
      "Set count: 7 Score: 0.39\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Best Update\n",
      "\n",
      "000101010\n",
      "0 (160, 'bcb') \t0.55\n",
      "1 (128, 'NNN') \t0.01\n",
      "2 (6, 'jkl') \t0.43\n",
      "3 (5, 'AAA') \t0.08\n",
      "4 (6, 'VUW') \t0.75\n",
      "5 (5, 'III') \t0.09\n",
      "6 (4, '[\\\\[') \t0.83\n",
      "Set count: 7 Score: 0.39\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================ \n",
      "Progress: 5 %\t 24 / 466\n",
      "================================================================================\n",
      "000110001\n",
      "0 (926, 'QQQ') \t0.07\n",
      "1 (128, 'JJJ') \t0.01\n",
      "2 (5, 'TTTUTT') \t0.97\n",
      "3 (7, 'HHH') \t0.08\n",
      "4 (16, 'LLL') \t0.07\n",
      "5 (4, 'AAA') \t0.08\n",
      "Set count: 6 Score: 0.21\n",
      "--------------------------------------------------------------------------------\n",
      "000110010\n",
      "0 (926, 'PPP') \t0.07\n",
      "1 (128, 'III') \t0.01\n",
      "2 (5, 'SSSTSS') \t0.97\n",
      "3 (7, 'GGG') \t0.08\n",
      "4 (16, 'KKK') \t0.07\n",
      "5 (5, 'AAA') \t0.07\n",
      "Set count: 6 Score: 0.21\n",
      "--------------------------------------------------------------------------------\n",
      "001000011\n",
      "0 (1483, 'AAA') \t0.10\n",
      "Set count: 1 Score: 0.10\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================ \n",
      "Progress: 10 %\t 47 / 466\n",
      "================================================================================\n",
      "001010010\n",
      "0 (989, 'BBB') \t0.00\n",
      "1 (5, 'AAA') \t0.09\n",
      "Set count: 2 Score: 0.05\n",
      "--------------------------------------------------------------------------------\n",
      "001100010\n",
      "0 (1206, 'JJJ') \t0.08\n",
      "1 (158, 'GGG') \t0.01\n",
      "2 (26, 'LLL') \t0.09\n",
      "3 (7, 'FFF') \t0.09\n",
      "4 (5, 'AAA') \t0.07\n",
      "Set count: 5 Score: 0.07\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================ \n",
      "Progress: 20 %\t 94 / 466\n",
      "================================================================================\n",
      "================================================================================ \n",
      "Progress: 30 %\t 140 / 466\n",
      "================================================================================\n",
      "011000010\n",
      "0 (1486, 'AAA') \t0.10\n",
      "Set count: 1 Score: 0.10\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================ \n",
      "Progress: 40 %\t 187 / 466\n",
      "================================================================================\n",
      "================================================================================ \n",
      "Progress: 50 %\t 233 / 466\n",
      "================================================================================\n",
      "================================================================================ \n",
      "Progress: 60 %\t 280 / 466\n",
      "================================================================================\n",
      "================================================================================ \n",
      "Progress: 70 %\t 327 / 466\n",
      "================================================================================\n",
      "================================================================================ \n",
      "Progress: 80 %\t 373 / 466\n",
      "================================================================================\n",
      "================================================================================ \n",
      "Progress: 90 %\t 420 / 466\n",
      "================================================================================\n",
      "================================================================================ \n",
      "Progress: 95 %\t 443 / 466\n",
      "================================================================================\n",
      "================================================================================ \n",
      "Progress: 99 %\t 462 / 466\n",
      "================================================================================\n",
      "================================================================================ \n",
      "Progress: 100 %\t 466 / 466\n",
      "================================================================================\n",
      "Best: {'option': '000101001', 'score': 0.39385429209338063, 'Set count': 7}\n"
     ]
    }
   ],
   "source": [
    "best = {'option':'000000000', 'score': 0}\n",
    "if find_encode == 1:\n",
    "    check_dict = {}\n",
    "    if brute == 1:\n",
    "        candidate = []\n",
    "        for i in range(1, 512):\n",
    "            tmp = binary('{0:b}'.format(i), 9)\n",
    "            if len(node_op.find_all_indexes(tmp, '1')) > 2:\n",
    "                candidate.append(tmp)\n",
    "    else:\n",
    "        #candidate = ['000110100', '000101010', '000101001']\n",
    "        with open('./good_encode.txt', 'rb') as f:\n",
    "            candidate = pickle.load(f)\n",
    "    total_progress = len(candidate)\n",
    "    progress = 0\n",
    "    progress_line = [0, 1, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 95, 99, 100, 101]\n",
    "    line_count = 0\n",
    "    check_dict = {}\n",
    "    for option in candidate:\n",
    "        progress += 1\n",
    "        while (progress/float(total_progress))*100 >= progress_line[line_count]:\n",
    "            print(\"=\"*80, \"\\nProgress:\", progress_line[line_count], \"%\\t\", progress, \"/\", total_progress)\n",
    "            print(\"=\"*80)\n",
    "            line_count += 1\n",
    "        encode_option = option\n",
    "        encode_col = [tag, ids, classes, pathid, parentid, tecid, cecid, encoding, col]\n",
    "        \"\"\"\n",
    "        Node op\n",
    "        ==================================================\n",
    "        \"\"\"\n",
    "        node_encode = node_op.encode_node(encode_col, encode_option, len(pathid))\n",
    "        whole_string = node_encode[0]\n",
    "        node_dict = node_encode[1] # code -> node num\n",
    "        index_dict = node_encode[2] # code -> first index\n",
    "        \"\"\"\n",
    "        ===================================================\n",
    "        \"\"\"\n",
    "        \n",
    "        inv_node_dict = {v: k for k, v in node_dict.items()} # node num -> code\n",
    "        inv_index_dict = {v: k for k, v in index_dict.items()} # index num -> code\n",
    "        if seg_method == 0:\n",
    "            segments = node_op.segment_mt(unique_mt, whole_string)\n",
    "            record_seg = node_op.mt_record_seg(segments, ignore_len, index_dict, inv_node_dict, MINIMAL_REPEAT)\n",
    "        if seg_method == 1:\n",
    "            segments, record_seg = node_op.segment_top(whole_string, ignore_len, index_dict, inv_node_dict, MINIMAL_REPEAT)\n",
    "        \n",
    "        all_seqs = node_op.get_all_seq(record_seg, segments)\n",
    "        if len(record_seg) > 0 and str(all_seqs) not in check_dict.keys():\n",
    "            check_dict[str(all_seqs)] = 1\n",
    "            seq_score = []\n",
    "            for seg_idx in range(len(all_seqs)):\n",
    "                appear = {}\n",
    "                score = 0.0\n",
    "                length_min_max = [999, 0]\n",
    "                for pattern in all_seqs[seg_idx][:-1]:\n",
    "                    if len(pattern) < length_min_max[0]:\n",
    "                        length_min_max[0] = len(pattern)\n",
    "                    if len(pattern) > length_min_max[1]:\n",
    "                        length_min_max[1] = len(pattern)\n",
    "                \n",
    "                score = np.amin(cosine_similarity(node_op.to_vector(all_seqs)[seg_idx]))\n",
    "                if length_min_max[1] == 1 or length_min_max[0] == 1:\n",
    "                    seq_score.append(score/10)\n",
    "                else: seq_score.append(score)\n",
    "            total_score = 0\n",
    "            print(option)\n",
    "            for s in range(len(record_seg)):\n",
    "                print(s, record_seg[s][1], \"\\t%.2f\" %(seq_score[s]))\n",
    "                repeat_time = record_seg[s][1][0]\n",
    "                total_score += seq_score[s]#/ pow(2, s)\n",
    "            #print(all_seqs)\n",
    "            print(\"Set count:\", len(record_seg), \"Score:\", \"%.2f\" %(total_score/len(record_seg)))\n",
    "            print('-'*80)\n",
    "            average = total_score/len(record_seg)\n",
    "            if average >= best['score']:\n",
    "                print(\"\\nBest Update\\n\")\n",
    "                best['score'] = average\n",
    "                best['Set count'] = len(record_seg)\n",
    "                best['option'] = option\n",
    "            \"\"\"if repeat_time < best['repeat_time']:\n",
    "                best['score'] = average\n",
    "                best['Set count'] = len(record_seg)\n",
    "                best['option'] = option\n",
    "            elif repeat_time == best['repeat_time'] and total_score > best['score']:\n",
    "                best['score'] = average\n",
    "                best['Set count'] = len(record_seg)\n",
    "                best['option'] = option\"\"\"\n",
    "print(\"Best:\", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: \n",
      "1229-16MT"
     ]
    }
   ],
   "source": [
    "if find_encode == 1:\n",
    "    encode_option = best['option']\n",
    "else:\n",
    "    #encode_option = '000110100'\n",
    "    encode_option = '000011010'\n",
    "\n",
    "encode_col = [tag, ids, classes, pathid, parentid, tecid, cecid, encoding, col]\n",
    "\"\"\"\n",
    "Node op\n",
    "==================================================\n",
    "\"\"\"\n",
    "node_encode = node_op.encode_node(encode_col, encode_option, len(pathid))\n",
    "whole_string = node_encode[0]\n",
    "node_dict = node_encode[1] # code -> node num\n",
    "index_dict = node_encode[2] # code -> first index\n",
    "\"\"\"\n",
    "===================================================\n",
    "\"\"\"\n",
    "print(\"Example: \")\n",
    "\n",
    "for col_num in range(len(encode_col)):\n",
    "    if encode_option[col_num] == '1':\n",
    "        print(encode_col[col_num][node], end='')\n",
    "inv_node_dict = {v: k for k, v in node_dict.items()} # node num -> code\n",
    "inv_index_dict = {v: k for k, v in index_dict.items()} # index num -> code\n",
    "#print(\"\\nConvert to Unicode String:\\n\", whole_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment whole string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if seg_method == 0:\n",
    "    segments = node_op.segment_mt(unique_mt, whole_string)\n",
    "    record_seg = node_op.mt_record_seg(segments, ignore_len, index_dict, inv_node_dict, MINIMAL_REPEAT)\n",
    "if seg_method == 1:\n",
    "    segments, record_seg = node_op.segment_top(whole_string, ignore_len, index_dict, inv_node_dict, MINIMAL_REPEAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdccef^_`ab', 'cd', 'cdcdef^_`abcaga', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef`abcagacdef^_`ab', 'cd', 'cdcdef`abcagacdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cdcdef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`abcddef^_`ab', 'cdcdef^_`ab', 'cdcdef^_`ab', 'cdcdef^_`ab', 'cdcdef^_`ab', 'cdcdef^_`ab', 'cdcdef^_`ab', 'cdcdef^_`ab', 'cdcdef^_`ab', 'cdcdef^_`ab', 'cdcdef^_`ab', 'cdcdef^_`ab', 'cdcdef^_`ab', 'cdcdef^_`ab', 'cdcdef^_`ab', 'cdcdef^_`abcagadef^_`ab', 'cd', 'cdcdef^_`ab', 'cd', 'cdcdef^_`abcagadef^_`ab', 'cdcdef^_`ab', 'cdcdef^_`ab', 'cdcdef^_`ab', 'cd', 'cdcdef^_`abcddef^_`abcddefh'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'OOOMNPPPPPPPPPPPPMN', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'OOOKLJKQKKKJIRRRRSTSTUV'], ['klmj', 'klmn', 'klmj', 'klmj', 'klmj', 'klmopopq'], ['J', 'J', 'J', 'J', 'JJJKL'], ['WVXY', 'WVXY', 'WVXZ', 'WVXY', 'WVXY', 'WVXYWVWV'], ['A', 'A', 'A', 'AAADE'], ['\\\\]', '\\\\]', '\\\\]', '\\\\]\\\\\\\\\\\\\\\\']]\n"
     ]
    }
   ],
   "source": [
    "all_seqs = node_op.get_all_seq(record_seg, segments)\n",
    "print(all_seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First round MSA\n",
      " ====================================================================================================\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdccef^_`ab \n",
      "\t\t->  --cd---------c---cef^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`abcaga \n",
      "\t\t->  --cd---------c---def^_`abcaga\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef`abcagacdef^_`ab \n",
      "\t\t->  cdcdef`abcagac---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef`abcagacdef^_`ab \n",
      "\t\t->  cdcdef`abcagac---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef`ab \n",
      "\t\t->  --cd---------c---def--`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`abcddef^_`ab \n",
      "\t\t->  cdcdef^_`ab--cd--def^_`ab----\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cdcdef^_`abcagadef^_`ab \n",
      "\t\t->  cdcdef^_`ab--cagadef^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "cdcdef^_`abcagadef^_`ab \n",
      "\t\t->  cdcdef^_`ab--cagadef^_`ab----\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cdcdef^_`ab \n",
      "\t\t->  --cd---------c---def^_`ab----\n",
      "cd \n",
      "\t\t->  -------------c---d-----------\n",
      "First round MSA\n",
      " ====================================================================================================\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "OOOMNPPPPPPPPPPPPMN \n",
      "\t\t->  OOOMNPPPPPPPPPPPPMN\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "O \n",
      "\t\t->  --O----------------\n",
      "First round MSA\n",
      " ====================================================================================================\n",
      "klmj \n",
      "\t\t->  klmj\n",
      "klmn \n",
      "\t\t->  klmn\n",
      "klmj \n",
      "\t\t->  klmj\n",
      "klmj \n",
      "\t\t->  klmj\n",
      "klmj \n",
      "\t\t->  klmj\n",
      "First round MSA\n",
      " ====================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J \n",
      "\t\t->  J\n",
      "J \n",
      "\t\t->  J\n",
      "J \n",
      "\t\t->  J\n",
      "J \n",
      "\t\t->  J\n",
      "First round MSA\n",
      " ====================================================================================================\n",
      "WVXY \n",
      "\t\t->  WVXY\n",
      "WVXY \n",
      "\t\t->  WVXY\n",
      "WVXZ \n",
      "\t\t->  WVXZ\n",
      "WVXY \n",
      "\t\t->  WVXY\n",
      "WVXY \n",
      "\t\t->  WVXY\n",
      "First round MSA\n",
      " ====================================================================================================\n",
      "A \n",
      "\t\t->  A\n",
      "A \n",
      "\t\t->  A\n",
      "A \n",
      "\t\t->  A\n",
      "First round MSA\n",
      " ====================================================================================================\n",
      "\\] \n",
      "\t\t->  \\]\n",
      "\\] \n",
      "\t\t->  \\]\n",
      "\\] \n",
      "\t\t->  \\]\n"
     ]
    }
   ],
   "source": [
    "import cstar\n",
    "removed_whole_string = whole_string\n",
    "for seg_idx in range(len(all_seqs)):\n",
    "    json_result = []\n",
    "    print(\"First round MSA\\n\", \"=\"*100)\n",
    "    scores = [5, -4, -2] # matchScore, mismatchScore, gapScore\n",
    "    if len(all_seqs[seg_idx][:-1]) == 1:\n",
    "        msa = all_seqs[seg_idx][:-1]\n",
    "    else:\n",
    "        msa = cstar.CenterStar(scores, all_seqs[seg_idx][:-1]).msa()\n",
    "    trans_dict = {}\n",
    "    last_c = '-'\n",
    "    end_idx = 0\n",
    "\n",
    "    for i in range(len(msa)):\n",
    "        if msa[i][-1] != '-' and last_c not in trans_dict.keys() and drop_last == 0:\n",
    "            last_c = msa[i][-1]\n",
    "            trans_dict[last_c] = msa[i].replace('-', '')\n",
    "        if msa[i].replace('-', '') not in trans_dict.keys():\n",
    "            trans_dict[msa[i].replace('-', '')] = msa[i]\n",
    "        else: pass\n",
    "    for i in all_seqs[seg_idx][:-1]: print(i, \"\\n\\t\\t-> \", trans_dict[i])\n",
    "    if drop_last == 0:\n",
    "        print('='*100, \"\\nSecond round MSA\\n\")\n",
    "        msa_2 = cstar.CenterStar(scores, msa+[all_seqs[seg_idx][-1]]).msa()\n",
    "        trans_dict_2 = {}\n",
    "\n",
    "        for i in range(len(msa_2)):\n",
    "            if msa_2[i].replace('-', '') not in trans_dict_2.keys():\n",
    "                trans_dict_2[msa_2[i].replace('-', '')] = msa_2[i]\n",
    "            else: pass\n",
    "        for idx in range(len(trans_dict_2[trans_dict[last_c]])):\n",
    "            if trans_dict_2[trans_dict[last_c]][idx] == last_c:\n",
    "                end_idx = idx\n",
    "        for i in all_seqs[seg_idx]:\n",
    "            trans_dict_2[i] = trans_dict_2[i][:end_idx+1]\n",
    "            tmp = trans_dict_2[i][:end_idx+1].replace('-', '')\n",
    "            removed_whole_string = removed_whole_string.replace(tmp, '-'*len(tmp))\n",
    "            print(i, \"\\n\\t\\t-> \", trans_dict_2[i])\n",
    "\n",
    "        json_schema = [{} for i in range(len(trans_dict_2[list(trans_dict_2.keys())[0]]))]\n",
    "        schema_check = [0 for i in range(len(trans_dict_2[list(trans_dict_2.keys())[0]]))]\n",
    "    else:\n",
    "        json_schema = [{} for i in range(len(trans_dict[list(trans_dict.keys())[0]]))]\n",
    "        schema_check = [0 for i in range(len(trans_dict[list(trans_dict.keys())[0]]))]\n",
    "\n",
    "    with open(os.path.join(current_path, \"Output\", \"Set-\" + str(seg_idx) + \".txt\"), 'w', encoding='utf-8') as file:\n",
    "        for page in range(len(others)):\n",
    "            json_page = []\n",
    "            output_dict = {} # Record which pattern is used\n",
    "            if drop_last == 1:\n",
    "                length = len(all_seqs[seg_idx]) - 1\n",
    "            else:\n",
    "                length = len(all_seqs[seg_idx])\n",
    "            for s in range(length):\n",
    "                write_tmp = []\n",
    "                json_set = []\n",
    "                write_tmp.append(str(page) + \"-\" + str(seg_idx) + \"-\" + str(s) + \"\\t\")\n",
    "                tmp = node_op.find_all_indexes(whole_string, all_seqs[seg_idx][s])\n",
    "                if all_seqs[seg_idx][s] not in output_dict.keys():\n",
    "                    output_dict[all_seqs[seg_idx][s]] = 0\n",
    "                else:\n",
    "                    output_dict[all_seqs[seg_idx][s]] += 1\n",
    "                #print(\"start:\", tmp[output_dict[seqs[s]]], others[page][tmp[output_dict[seqs[s]]]])\n",
    "                idx = 0\n",
    "                if drop_last == 0:\n",
    "                    for c in range(len(trans_dict_2[all_seqs[seg_idx][s]])):\n",
    "                        if trans_dict_2[all_seqs[seg_idx][s]][c] == '-':\n",
    "                            write_tmp.append('\\t')\n",
    "                            json_set.append('')\n",
    "                        else:\n",
    "                            write_tmp.append(others[page][tmp[output_dict[all_seqs[seg_idx][s]]]+idx][:others[page][tmp[output_dict[all_seqs[seg_idx][s]]]+idx].find(\" ::\")] + \"\\t\")\n",
    "                            json_set.append(others[page][tmp[output_dict[all_seqs[seg_idx][s]]]+idx][:others[page][tmp[output_dict[all_seqs[seg_idx][s]]]+idx].find(\" ::\")])\n",
    "                            if schema_check[c] == 0:\n",
    "                                schema_check[c] = 1\n",
    "                                json_schema[c][\"PathId\"] = pathid[tmp[output_dict[all_seqs[seg_idx][s]]]+idx]\n",
    "                                json_schema[c][\"ParentId\"] = parentid[tmp[output_dict[all_seqs[seg_idx][s]]]+idx].split(':')[0].replace('\\\"', '')\n",
    "                                if encoding[tmp[output_dict[all_seqs[seg_idx][s]]]+idx] == ' ':\n",
    "                                    json_schema[c][\"Encoding\"] = ''\n",
    "                                else:\n",
    "                                    json_schema[c][\"Encoding\"] = int(encoding[tmp[output_dict[all_seqs[seg_idx][s]]]+idx])\n",
    "                                json_schema[c][\"CECId\"] = cecid[tmp[output_dict[all_seqs[seg_idx][s]]]+idx]\n",
    "                                json_schema[c][\"TECId\"] = tecid[tmp[output_dict[all_seqs[seg_idx][s]]]+idx]\n",
    "                                json_schema[c][\"ColType\"] = col[tmp[output_dict[all_seqs[seg_idx][s]]]+idx]\n",
    "                            idx += 1\n",
    "                    if len(list(c for c in write_tmp if c != '\\t' and c != '')) != 1:\n",
    "                        for word in write_tmp:\n",
    "                            file.write(word)\n",
    "                        file.write('\\n')\n",
    "                else:\n",
    "                    for c in range(len(trans_dict[all_seqs[seg_idx][s]])):\n",
    "                        if trans_dict[all_seqs[seg_idx][s]][c] == '-':\n",
    "                            write_tmp.append('\\t')\n",
    "                            json_set.append('')\n",
    "                        else:\n",
    "                            write_tmp.append(others[page][tmp[output_dict[all_seqs[seg_idx][s]]]+idx][:others[page][tmp[output_dict[all_seqs[seg_idx][s]]]+idx].find(\" ::\")] + \"\\t\")\n",
    "                            json_set.append(others[page][tmp[output_dict[all_seqs[seg_idx][s]]]+idx][:others[page][tmp[output_dict[all_seqs[seg_idx][s]]]+idx].find(\" ::\")])\n",
    "                            if schema_check[c] == 0:\n",
    "                                schema_check[c] = 1\n",
    "                                json_schema[c][\"PathId\"] = pathid[tmp[output_dict[all_seqs[seg_idx][s]]]+idx]\n",
    "                                json_schema[c][\"ParentId\"] = parentid[tmp[output_dict[all_seqs[seg_idx][s]]]+idx].split(':')[0].replace('\\\"', '')\n",
    "                                if encoding[tmp[output_dict[all_seqs[seg_idx][s]]]+idx] == ' ':\n",
    "                                    json_schema[c][\"Encoding\"] = ''\n",
    "                                else:\n",
    "                                    json_schema[c][\"Encoding\"] = int(encoding[tmp[output_dict[all_seqs[seg_idx][s]]]+idx])\n",
    "                                json_schema[c][\"CECId\"] = cecid[tmp[output_dict[all_seqs[seg_idx][s]]]+idx]\n",
    "                                json_schema[c][\"TECId\"] = tecid[tmp[output_dict[all_seqs[seg_idx][s]]]+idx]\n",
    "                                json_schema[c][\"ColType\"] = col[tmp[output_dict[all_seqs[seg_idx][s]]]+idx]\n",
    "                            idx += 1\n",
    "                    if len(list(c for c in write_tmp if c != '\\t' and c != '')) != 1:\n",
    "                        for word in write_tmp:\n",
    "                            file.write(word)\n",
    "                        file.write('\\n')\n",
    "                json_page.append(json_set)\n",
    "            json_result.append(json_page)\n",
    "    with open(os.path.join(current_path, \"Output\", \"Set-\" + str(seg_idx) + \"_schema.json\"), 'w') as json_file:\n",
    "        json.dump(json_result, json_file)\n",
    "    with open(os.path.join(current_path, \"Output\", \"Set-\" + str(seg_idx) + \"_schema.json\"), 'w') as json_file:\n",
    "        json.dump(json_schema, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified TableA Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_table = []\n",
    "json_schema = []\n",
    "for page in range(len(others)):\n",
    "    json_page = []\n",
    "    set_count = 0\n",
    "    check = False\n",
    "    for node in range(len(removed_whole_string)):\n",
    "        schema_dict = {}\n",
    "        if removed_whole_string[node] == '-':\n",
    "            if check == False:\n",
    "                check = True\n",
    "                set_count += 1\n",
    "                json_page.append(str(set_count) + '-' + str(page))\n",
    "                schema_dict[\"PathId\"] = \"\"\n",
    "                schema_dict[\"ParentId\"] = \"\"\n",
    "                schema_dict[\"Encoding\"] = -1\n",
    "                schema_dict[\"CECId\"] = \"\"\n",
    "                schema_dict[\"TECId\"] = \"\"\n",
    "                schema_dict[\"ColType\"] = \"MR\"\n",
    "                json_schema.append(schema_dict)\n",
    "            else: pass\n",
    "        else:\n",
    "            if check == True:\n",
    "                check = False\n",
    "            json_page.append(others[page][node][:others[page][node].find(\" ::\")])\n",
    "            schema_dict[\"PathId\"] = pathid[node]\n",
    "            schema_dict[\"ParentId\"] = parentid[node].split(':')[0].replace('\\\"', '')\n",
    "            if encoding[node] != ' ':\n",
    "                schema_dict[\"Encoding\"] = int(encoding[node])\n",
    "            else:\n",
    "                schema_dict[\"Encoding\"] = ''\n",
    "            schema_dict[\"CECId\"] = cecid[node]\n",
    "            schema_dict[\"TECId\"] = tecid[node]\n",
    "            schema_dict[\"ColType\"] = col[node]\n",
    "            json_schema.append(schema_dict)\n",
    "    json_table.append(json_page)\n",
    "with open(os.path.join(current_path, \"Output\", \"TableA.json\"), 'w') as json_file:\n",
    "    json.dump(json_table, json_file)\n",
    "with open(os.path.join(current_path, \"Output\", \"SchemaTableA.json\"), 'w') as json_file:\n",
    "    json.dump(json_schema, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./good_encode.txt', 'rb') as f:\n",
    "    candidate = pickle.load(f)\n",
    "if best['option'] not in candidate and brute == 1:\n",
    "    with open('./good_encode.txt', 'wb') as f:\n",
    "        candidate.append(best['option'])\n",
    "        print(\"Append:\", best['option'])\n",
    "        pickle.dump(candidate, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000011010',\n",
       " '000001011',\n",
       " '000100011',\n",
       " '000001101',\n",
       " '000101001',\n",
       " '000110010',\n",
       " '000101010',\n",
       " '011000010',\n",
       " '000110001',\n",
       " '001010010',\n",
       " '000000111',\n",
       " '000010011',\n",
       " '000001110',\n",
       " '001000011']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if brute == 1:\n",
    "    with open('./good_encode.txt', 'rb') as f:\n",
    "        candidate = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#candidate = candidate[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if brute == 1:\n",
    "    with open('./good_encode.txt', 'wb') as f:\n",
    "        pickle.dump(candidate, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 Set\n",
      "BEST:  {'option': '000101001', 'score': 0.39385429209338063, 'Set count': 7}\n"
     ]
    }
   ],
   "source": [
    "print(len(all_seqs), \"Set\\nBEST: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ignore_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
